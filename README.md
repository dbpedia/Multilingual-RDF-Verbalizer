# neural-rdf-verbalizer-gsoc-2020
GSoC 2020 


## 1) Generating a Knowledge Subgraph for WebNLG dataset

Firstly, you need to generate a subgraph of the dbpedia files using the subjects in the vocabulary of the webnlg dataset. To do this, you should run the following script:
```
cd tools
python3.6 build_subgraph_from_webnlg.py \
   -webnlg <all train/dev/test split in the WebNLG dataset. Example: dataset/challenge2020_train_dev/en/train dataset/challenge2020_train_dev/en/dev > \
   -dbpedia <put all .ttl files of the Knowledge Base> \
   -max-depth <Max. depth path per instance> \
   -output <path for saving the Knowledge subgraph>
```

## 2) Node embeddings generation

All algorithms to generate node embeddings are obtained from the subgraph previously generated.


### RDF2Vec

Folder rdf2vec contains the same code as [pyRDF2Vec] with some small modifications for generating node embeddings in the WebNLG.

To run:
```
    cd rdf2vec
    python3.6 execute.py 
       -dbpedia <path of the dbpedia file(s). Usually a .ttl> \
       -vocab <vocabulary. It could be a pickle> -embed-size 300 -depth 8 \
       -algorithm rnd -walks 200 -jobs 5 -window 5 -sg \
       -max-iter 30 -negative 25 -min-count 1 -oe subgraph_embeddings -seed 13 \
       -webnlg <You can add the WebNLG folders to enrich the dbpedia files wich relations/properties that are not part of the original dbpedia files. Ex. dataset/challenge2020_train_dev/en/train> -sup <if you want to add a supplementary information for the WebNLG dataset (modified relations/properties). Ex. ../dataset/supplementary>
```

### PYKE

Folder pyke contains the same code as [PYKE] with some small modifications for generating node embeddings in the WebNLG.

To install: ./install_pyke.sh | conda activate pyke


To run:
```
    cd PYKE
    python3.6 execute.py --kg_path KGs/webnlg-dbpedia/subgraph_webnlg.ttl \
        --embedding_dim 300 --num_iterations 1000 --K 45 --omega 0.45557 \
        --energy_release 0.0414 --webnlg <The same idea as the rdf2vec, optional> \
        --sup <The same idea as the rdf2vec, optional> \
        --output-name <path of the output file (csv format)>
```

PYKE generates a .csv file, so, you need to run a script to get the embeddings (vocabulary in json and embedding matrix in a numpy array). Json and Numpy files will have the same name as the csv file.
```
    cd PYKE
    python3.6 get_embeddings.py -csv <csv file> -embed-size <embedding size, generated by PYKE>

```





[pyRDF2Vec]: https://github.com/IBCNServices/pyRDF2Vec
[PYKE]: https://github.com/dice-group/PYKE
